# ============================================
# NL2SQL Enterprise Agent (RAG + ReAct + Time-Aware)
# ============================================
import os
import yaml
import json
import datetime
import logging
from typing import TypedDict, Annotated, List, Literal, Optional

# --- LangChain / LangGraph Imports ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END
from langchain_community.utilities import SQLDatabase
from langchain_community.vectorstores import FAISS

# ==========================================
# 1. é…ç½®åŠ è½½å™¨
# ==========================================
class ConfigManager:
    _instance = None
    _config = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ConfigManager, cls).__new__(cls)
            cls._instance._load_config()
        return cls._instance

    def _load_config(self, path="dev.yaml"):
        if not os.path.exists(path):
            raise FileNotFoundError(f"CRITICAL: é…ç½®æ–‡ä»¶ {path} ä¸å­˜åœ¨ï¼")
        
        with open(path, 'r', encoding='utf-8') as f:
            self._config = yaml.safe_load(f)
        
        log_path = self._config['logging']['file_path']
        os.makedirs(os.path.dirname(log_path), exist_ok=True)

    @property
    def config(self):
        return self._config

cfg = ConfigManager().config

# ==========================================
# 2. æ•°æ®åº“ä¸ RAG æ£€ç´¢å¼•æ“ (æ ¸å¿ƒå‡çº§)
# ==========================================
class DBManager:
    _instance = None
    _db = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(DBManager, cls).__new__(cls)
            db_uri = cfg['db']['uri']
            cls._instance._db = SQLDatabase.from_uri(db_uri)
        return cls._instance

    @property
    def db(self):
        return self._db

    def get_table_info(self, table_names: List[str] = None) -> str:
        all_tables = self._db.get_usable_table_names()
        if not table_names:
            return self._db.get_table_info(all_tables)
        
        # ä¸¥æ ¼è¿‡æ»¤ï¼Œé˜²æ­¢ LLM å¹»è§‰å‡ºçš„è¡¨åå¯¼è‡´æŠ¥é”™
        valid_tables = [t for t in table_names if t in all_tables]
        return self._db.get_table_info(valid_tables)

db_manager = DBManager()

# --- [æ–°å¢] Schema æ£€ç´¢å™¨ (RAG) ---
class SchemaRetriever:
    _instance = None
    _vector_store = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(SchemaRetriever, cls).__new__(cls)
            cls._instance._initialize_index()
        return cls._instance
    
    def _initialize_index(self):
        """æ„å»ºå‘é‡ç´¢å¼•ï¼šå°†æ‰€æœ‰è¡¨åå’Œç»“æ„å‘é‡åŒ–"""
        print("ğŸ“¥ [System] æ­£åœ¨æ„å»º Schema å‘é‡ç´¢å¼• (RAG)...")
        table_names = db_manager.db.get_usable_table_names()
        docs = []
        
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åªç´¢å¼•è¡¨åå’ŒåŸºç¡€ DDLã€‚
        # ç”Ÿäº§ç¯å¢ƒå»ºè®®ç´¢å¼•è¡¨çš„ COMMENT æ³¨é‡Šï¼Œä»¥æ”¯æŒæ¨¡ç³Šè¯­ä¹‰æœç´¢ã€‚
        for t in table_names:
            # è·å–è¯¥è¡¨çš„ DDL ä½œä¸ºå†…å®¹
            ddl = db_manager.db.get_table_info([t])
            # Metadata è®°å½•è¡¨å
            docs.append(Document(page_content=f"Table Name: {t}\nSchema: {ddl}", metadata={"table_name": t}))
            
        if docs:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            self._vector_store = FAISS.from_documents(docs, embeddings)
            print(f"   âœ… å·²ç´¢å¼• {len(docs)} å¼ è¡¨ã€‚")
        else:
            print("   âš ï¸ è­¦å‘Š: æ•°æ®åº“ä¸ºç©ºï¼Œè·³è¿‡ç´¢å¼•æ„å»ºã€‚")

    def retrieve_relevant_schemas(self, query: str, top_k: int = 3) -> str:
        """æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œæ£€ç´¢æœ€ç›¸å…³çš„è¡¨ç»“æ„"""
        if not self._vector_store:
            return db_manager.get_table_info() # å…œåº•ï¼šè¿”å›æ‰€æœ‰
            
        print(f"   ğŸ” [RAG] æ­£åœ¨æ£€ç´¢ä¸ '{query}' ç›¸å…³çš„è¡¨...")
        docs = self._vector_store.similarity_search(query, k=top_k)
        
        retrieved_tables = [d.metadata['table_name'] for d in docs]
        # å»é‡
        retrieved_tables = list(set(retrieved_tables))
        print(f"   ğŸ¯ [RAG] å‘½ä¸­è¡¨: {retrieved_tables}")
        
        return db_manager.get_table_info(retrieved_tables)

# åˆå§‹åŒ– RAG å¼•æ“ (å¯åŠ¨æ—¶åŠ è½½)
schema_retriever = SchemaRetriever()

# ==========================================
# 3. çŠ¶æ€å®šä¹‰
# ==========================================
class IntentResult(BaseModel):
    query_type: Literal["statistic", "query", "sort", "unknown"] = Field(...)
    # æ³¨æ„ï¼šæœ‰äº† RAGï¼ŒIntent é˜¶æ®µæå–è¡¨åçš„å‹åŠ›å˜å°äº†ï¼Œä½†ä¿ç•™å®ƒä½œä¸ºè¾…åŠ©æ ¡éªŒä¾ç„¶å¾ˆå¥½
    keywords: List[str] = Field(default=[])
    complexity: Literal["simple", "complex"] = Field(...)

class AgentState(TypedDict):
    user_input: str
    intent: Optional[dict]
    schema_context: Optional[str]
    generated_sql: Optional[str]
    query_result: Optional[str]
    final_answer: Optional[str]
    error: Optional[str]
    retry_count: int
    approval_status: Optional[str]

# ==========================================
# 4. è·¯ç”±é€»è¾‘
# ==========================================
MAX_RETRIES = 3

def check_is_risky(sql: str) -> bool:
    """
    æ£€æŸ¥ SQL æ˜¯å¦åŒ…å«é«˜å±æ“ä½œ æˆ– æ•æ„Ÿæ•°æ®è®¿é—®
    """
    if not sql: return False
    
    sql_upper = sql.upper()
    
    # 1. [æ•°æ®ç ´åé£é™©] DML/DDL å…³é”®è¯
    # æ–‡ä¸­æåˆ°: UPDATE, INSERT, DELETE, DROP TABLE
    destructive_keywords = ["DELETE", "UPDATE", "DROP", "ALTER", "TRUNCATE", "INSERT", "GRANT", "REVOKE"]
    for kw in destructive_keywords:
        if kw in sql_upper:
            print(f"   ğŸ›¡ï¸ [Security] æ‹¦æˆªç ´åæ€§æ“ä½œ: {kw}")
            return True
            
    # 2. [æ•°æ®æ³„éœ²é£é™©] æ•æ„Ÿå­—æ®µå…³é”®è¯
    # æ–‡ä¸­æåˆ°: "æŸ¥è¯¢åˆ°å®ƒæœ¬ä¸åº”è®¿é—®çš„æ•æ„Ÿæ•°æ®ï¼ˆå¦‚ç”¨æˆ·å¯†ç ï¼‰"
    sensitive_keywords = ["PASSWORD", "PASSWD", "SECRET", "HASH", "TOKEN", "API_KEY", "SALARY", "CREDIT_CARD"]
    for kw in sensitive_keywords:
        if kw in sql_upper:
            print(f"   ğŸ›¡ï¸ [Security] æ‹¦æˆªæ•æ„Ÿæ•°æ®è®¿é—®: {kw}")
            return True
            
    return False

def check_safety_router(state: AgentState) -> Literal["approve", "execute"]:
    if check_is_risky(state.get("generated_sql", "")):
        print(f"   ğŸ›¡ï¸ [Router] é£é™©æ“ä½œæ‹¦æˆª -> äººå·¥å®¡æ‰¹")
        return "approve"
    return "execute"

def post_approval_router(state: AgentState) -> Literal["execute", "reject"]:
    if state.get("approval_status") == "approved":
        return "execute"
    return "reject"

def should_continue(state: AgentState) -> Literal["retry", "synthesize"]:
    error = state.get("error")
    retries = state.get("retry_count", 0)
    if error:
        if retries < MAX_RETRIES:
            print(f"   ğŸ”„ [Router] è§¦å‘ ReAct ä¿®æ­£ (å‰©ä½™æ¬¡æ•°: {MAX_RETRIES - retries - 1})")
            return "retry"
        else:
            print(f"   ğŸ›‘ [Router] è¶…è¿‡é‡è¯•ä¸Šé™ -> åœæ­¢")
            return "synthesize"
    return "synthesize"

# ==========================================
# 5. èŠ‚ç‚¹å®ç°
# ==========================================

def parse_intent_node(state: AgentState):
    print(f"\nğŸš€ [Node: Intent] åˆ†æ: {state['user_input']}")
    llm = ChatOpenAI(model=cfg['llm']['model_name'], temperature=0)
    structured_llm = llm.with_structured_output(IntentResult)
    
    # å¢åŠ  rewrite æŒ‡ä»¤ï¼Œåšè½»é‡çº§çš„é—®é¢˜æ ‡å‡†åŒ–
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®åº“ä¸“å®¶ã€‚åˆ†æç”¨æˆ·æ„å›¾ã€‚
    å¦‚æœç”¨æˆ·è¾“å…¥æ¨¡ç³Šï¼ˆå¦‚â€œæŸ¥ä¸‹é‚£ä¸ªå•¥â€ï¼‰ï¼Œè¯·å°½åŠ›æ¨æ–­ã€‚"""
    
    try:
        prompt = ChatPromptTemplate.from_messages([("system", system_prompt), ("human", "{input}")])
        result = (prompt | structured_llm).invoke({"input": state['user_input']})
        print(f"   âœ… æ„å›¾: {result.query_type}")
        return {"intent": result.dict()}
    except Exception as e:
        return {"error": f"Intent Error: {e}"}

def generate_sql_node(state: AgentState):
    print(f"\nâš™ï¸ [Node: Generate SQL] ...")
    current_retries = state.get("retry_count", 0)
    user_input = state['user_input']
    
    # --- [Time Aware] æ—¶é—´æ³¨å…¥ ---
    now = datetime.datetime.now()
    current_time_str = now.strftime("%Y-%m-%d %H:%M:%S")
    weekday_str = now.strftime("%A")
    
    # --- [RAG] åŠ¨æ€ Schema æ£€ç´¢ ---
    if not state.get("schema_context"):
        schema_context = schema_retriever.retrieve_relevant_schemas(user_input, top_k=3)
    else:
        schema_context = state["schema_context"]

    llm = ChatOpenAI(model=cfg['llm']['model_name'], temperature=0)
    
    # --- [Optimization] å¼•å…¥ Few-Shot ç¤ºä¾‹ (æºè‡ªæ–‡æ¡£å»ºè®®) ---
    few_shot_examples = """
    ã€å‚è€ƒç¤ºä¾‹ã€‘
    é—®é¢˜: "æ˜¾ç¤ºæ‰€æœ‰å®¢æˆ·åŠå…¶è®¢å•æ•°é‡ã€‚"
    SQL: SELECT c.name, COUNT(o.order_id) FROM customers c LEFT JOIN orders o ON c.id = o.customer_id GROUP BY c.name;
    
    é—®é¢˜: "å“ªä¸ªäº§å“çš„å•ç¬”è®¢å•é‡‘é¢æœ€é«˜ï¼Ÿ"
    SQL: SELECT product, amount FROM orders ORDER BY amount DESC LIMIT 1;
    """
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ª SQL ç”Ÿæˆä¸“å®¶ã€‚
    
    ã€ç¯å¢ƒä¿¡æ¯ã€‘
    å½“å‰æ—¶é—´: {current_time_str} ({weekday_str})
    æ•°æ®åº“: SQLite
    
    ã€ç›¸å…³è¡¨ç»“æ„ã€‘
    {schema_context}
    
    {few_shot_examples}

    ã€ä»»åŠ¡ã€‘
    è¯·æ ¹æ®Schemaç¼–å†™SQLã€‚åªè¾“å‡º SQL è¯­å¥ï¼Œæ—  Markdownã€‚
    æ³¨æ„ï¼š
    1. æ¶‰åŠæ—¥æœŸæŸ¥è¯¢æ—¶ï¼Œè¯·å‚è€ƒã€å½“å‰æ—¶é—´ã€‘ã€‚
    2. ä¸¥æ ¼éµå¾ªç¤ºä¾‹ä¸­çš„ JOIN å’Œèšåˆé€»è¾‘ã€‚
    """
    
    user_prompt = f"ç”¨æˆ·é—®é¢˜: {user_input}"
    
    # ReAct é”™è¯¯ä¿®æ­£ä¸Šä¸‹æ–‡
    last_error = state.get("error")
    if last_error and current_retries > 0:
        print(f"   âš ï¸ [Self-Correction] æ³¨å…¥ä¸Šè½®é”™è¯¯ä¿¡æ¯...")
        user_prompt += f"\n\nä¸Šä¸€è½® SQL: {state.get('generated_sql')}\næŠ¥é”™ä¿¡æ¯: {last_error}\nè¯·ä¿®æ­£ SQLã€‚"
        
    prompt = ChatPromptTemplate.from_messages([("system", system_prompt), ("human", user_prompt)])
    
    try:
        response = (prompt | llm).invoke({})
        sql = response.content.strip().replace("```sql", "").replace("```", "")
        print(f"   ğŸ’» SQL: {sql}")
        return {"generated_sql": sql, "schema_context": schema_context}
    except Exception as e:
        return {"error": f"Gen Error: {e}"}

def human_approval_node(state: AgentState):
    print(f"\nâœ‹ [Node: Approval] âš ï¸ é«˜å± SQL æ‹¦æˆª: {state.get('generated_sql')}")
    try:
        decision = input("   ğŸ‘®â€â™‚ï¸ å…è®¸æ‰§è¡Œå—? (yes/no): ").strip().lower()
    except: decision = "no"
    
    if decision == "yes":
        return {"approval_status": "approved"}
    return {"approval_status": "rejected", "error": "User rejected execution."}

def execute_sql_node(state: AgentState):
    print(f"\nâš¡ [Node: Execute] ...")
    sql = state.get("generated_sql")
    if not sql: return {"error": "No SQL"}
    
    try:
        result = db_manager.db.run(sql)
        print(f"   âœ… ç»“æœ: {str(result)[:100]}...") # åªæ‰“å°å‰100å­—ç¬¦
        return {"query_result": str(result), "error": None} # æˆåŠŸå¿…é¡»æ¸…é™¤ error
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        return {"error": str(e)}

def prepare_retry_node(state: AgentState):
    return {"retry_count": state.get("retry_count", 0) + 1}

def synthesize_answer_node(state: AgentState):
    print(f"\nğŸ—£ï¸ [Node: Synthesize] ...")
    error = state.get("error")
    if error:
        return {"final_answer": f"æŠ±æ­‰ï¼Œé‡åˆ°é—®é¢˜: {error}"}
    
    llm = ChatOpenAI(model=cfg['llm']['model_name'], temperature=0.5)
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚æ ¹æ®æ•°æ®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚ä¿ç•™ä¸¤ä½å°æ•°ã€‚"
    user_prompt = f"é—®é¢˜: {state['user_input']}\nSQL: {state.get('generated_sql')}\næ•°æ®: {state.get('query_result')}"
    
    try:
        res = (ChatPromptTemplate.from_messages([("system", system_prompt), ("human", user_prompt)]) | llm).invoke({})
        print(f"   ğŸ¤– å›ç­”: {res.content}")
        return {"final_answer": res.content}
    except Exception as e:
        return {"final_answer": "åˆæˆå¤±è´¥", "error": str(e)}

def log_node(state: AgentState):
    log_file = cfg['logging']['file_path']
    entry = {
        "ts": datetime.datetime.now().isoformat(),
        "query": state["user_input"],
        "sql": state.get("generated_sql"),
        "error": state.get("error")
    }
    try:
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    except: pass
    return {}

# ==========================================
# 6. æ„å»ºå›¾
# ==========================================
def build_graph():
    workflow = StateGraph(AgentState)

    workflow.add_node("parse_intent", parse_intent_node)
    workflow.add_node("generate_sql", generate_sql_node)
    workflow.add_node("human_approval", human_approval_node)
    workflow.add_node("execute_sql", execute_sql_node)
    workflow.add_node("prepare_retry", prepare_retry_node)
    workflow.add_node("synthesize_answer", synthesize_answer_node)
    workflow.add_node("audit_log", log_node)

    workflow.set_entry_point("parse_intent")
    
    workflow.add_edge("parse_intent", "generate_sql")
    
    workflow.add_conditional_edges(
        "generate_sql", 
        check_safety_router, 
        {"approve": "human_approval", "execute": "execute_sql"}
    )
    
    workflow.add_conditional_edges(
        "human_approval",
        post_approval_router,
        {"execute": "execute_sql", "reject": "synthesize_answer"}
    )

    # ReAct æ ¸å¿ƒé—­ç¯
    workflow.add_conditional_edges(
        "execute_sql",
        should_continue,
        {"retry": "prepare_retry", "synthesize": "synthesize_answer"}
    )
    
    workflow.add_edge("prepare_retry", "generate_sql")
    workflow.add_edge("synthesize_answer", "audit_log")
    workflow.add_edge("audit_log", END)

    return workflow.compile()

# ==========================================
# Main
# ==========================================
if __name__ == "__main__":
    if "OPENAI_API_KEY" not in os.environ:
        print("âš ï¸ è¯·è®¾ç½® OPENAI_API_KEY")
    
    app = build_graph()
    
    # æµ‹è¯• 1 æ¨¡ç³Šè¡¨å (æµ‹è¯• RAG)
    # å‡è®¾æœ‰ä¸€ä¸ªè¡¨å« 'orders'ï¼Œç”¨æˆ·åªè¯´ 'ä¹°å–è®°å½•'ï¼ŒRAG åº”èƒ½é€šè¿‡æ³¨é‡Šå…³è”(éœ€å®Œå–„DDLæ³¨é‡Š)
    # è¿™é‡Œæµ‹è¯• RAG çš„è¡¨åè¿‡æ»¤åŠŸèƒ½
    print("-" * 50)
    app.invoke({"user_input": "Alice æœ€è¿‘æœ‰æ²¡æœ‰ä¹°è¿‡ Laptopï¼Ÿ"})
    
    # æµ‹è¯• 2 æ—¶é—´æ„ŸçŸ¥
    print("\n" + "-" * 50)
    app.invoke({"user_input": "ä¸Šä¸ªæœˆçš„æ‰€æœ‰è®¢å•æ€»é¢æ˜¯å¤šå°‘ï¼Ÿ"})
    
    print("\nâœ… ç³»ç»Ÿæµ‹è¯•å®Œæˆã€‚")
   
    # æµ‹è¯•3 å¸¸è§„æŸ¥è¯¢
    print(f"ğŸ å¼€å§‹æµ‹è¯•å¸¸è§„æŸ¥è¯¢...")
    app.invoke({"user_input": "ç»Ÿè®¡ New York ç”¨æˆ·çš„è®¢å•æ€»é¢"})
    
    # æµ‹è¯• 4 é«˜å±æ‹¦æˆª
    print("\n" + "-" * 50)
    print("ğŸ§¨ å¼€å§‹æµ‹è¯•é«˜å±æ‹¦æˆª (è¯·è¾“å…¥ no æ‹’ç»)...")
    app.invoke({"user_input": "æŠŠ Alice çš„è®¢å•é‡‘é¢å…¨éƒ¨æ”¹æˆ 0"})